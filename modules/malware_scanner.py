"""Malware Scanner — detect cryptominers, SEO spam, redirects, skimmers in responses."""

import aiohttp
import asyncio
import re
from urllib.parse import urljoin
from modules.core import console

CRYPTOMINER_SIGS = [
    'coinhive.min.js', 'coinhive', 'CoinHive', 'crypto-loot', 'cryptoloot',
    'coin-hive', 'jsecoin', 'miner.start', 'CryptoNoter', 'deepMiner',
    'cloudcoins', 'webminepool', 'BrowserMiner', 'GridCash', 'PPoi',
    'CoinImp', 'coinimp.com', 'jsE.minr', 'webmine.pro', 'authedmine',
]

SEO_SPAM_SIGS = [
    'viagra', 'cialis', 'casino', 'poker', 'slots', 'gambling', 'pharma',
    'cheap-pills', 'buy-online', 'hacked by', 'defaced by', 'owned by',
    'japanese seo spam', 'cloaking', 'doorway page',
]

SKIMMER_SIGS = [
    'formjacking', 'magecart', 'credit card', 'cc_number', 'card_number',
    'payment_data', 'skimmer', 'exfil_data', 'steal_form',
    'document.forms', 'querySelector.*payment', 'input[name*=card]',
]

REDIRECT_MALWARE = [
    (r'<meta\s+http-equiv\s*=\s*["\']refresh["\'][^>]*url\s*=\s*["\']?https?://(?!.*(?:google|facebook|twitter))', 'Meta refresh redirect'),
    (r'window\.location\s*=\s*["\']https?://[^"\']*(?:\.xyz|\.tk|\.top|\.pw)', 'JS redirect to suspicious TLD'),
    (r'document\.location\s*=', 'Document location change'),
    (r'top\.location\s*=', 'Frame-busting redirect'),
    (r'window\.open\s*\(\s*["\']https?://[^"\']*(?:ads|click|track)', 'Popup ad/tracker'),
]

MALWARE_DOMAINS = [
    '.xyz/track', '.tk/redir', 'evil.com', 'malware-domain', 'drive-by',
    'cdn.statistic', 'analytics-counter', 'google-analytics.cm',
    'googletagmanager.cm', 'addthis.cm', 'facebook.cm',
]


async def _scan_page_malware(session, url):
    findings = []
    pages = [url, urljoin(url, '/?p=1'), urljoin(url, '/page/1')]

    for page in pages:
        try:
            async with session.get(page, timeout=aiohttp.ClientTimeout(total=10), ssl=False) as resp:
                if resp.status == 200:
                    body = await resp.text()

                    for sig in CRYPTOMINER_SIGS:
                        if sig.lower() in body.lower():
                            findings.append({'type': f'Cryptominer: {sig}', 'url': page, 'severity': 'Critical'})
                            break

                    body_lower = body.lower()
                    spam_count = sum(1 for s in SEO_SPAM_SIGS if s in body_lower)
                    if spam_count >= 3:
                        findings.append({'type': f'SEO Spam ({spam_count} indicators)', 'url': page, 'severity': 'High'})

                    for sig in SKIMMER_SIGS:
                        if sig.lower() in body_lower:
                            findings.append({'type': f'Payment Skimmer: {sig}', 'url': page, 'severity': 'Critical'})
                            break

                    for pattern, desc in REDIRECT_MALWARE:
                        if re.search(pattern, body, re.I):
                            findings.append({'type': f'Malicious Redirect: {desc}', 'url': page, 'severity': 'Critical'})
                            break

                    for domain in MALWARE_DOMAINS:
                        if domain in body_lower:
                            findings.append({'type': f'Malware Domain: {domain}', 'url': page, 'severity': 'High'})
                            break

                    obfuscated = re.findall(r'<script[^>]*>[^<]*(?:eval|unescape|fromCharCode)[^<]{200,}</script>', body, re.I | re.S)
                    if obfuscated:
                        findings.append({'type': f'Obfuscated Malware Script', 'url': page,
                                         'severity': 'Critical', 'count': len(obfuscated)})
        except Exception:
            pass
    return findings


async def _check_google_safebrowsing(session, url):
    findings = []
    try:
        check_url = f'https://transparencyreport.google.com/safe-browsing/search?url={url}'
        findings.append({'type': f'Check Google Safe Browsing', 'url': check_url, 'severity': 'Info',
                         'detail': 'Visit URL to check blacklist status'})
    except Exception:
        pass
    return findings


async def _scan_external_resources(session, url):
    findings = []
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10), ssl=False) as resp:
            if resp.status == 200:
                body = await resp.text()
                ext_scripts = re.findall(r'<script[^>]*src=["\']([^"\']+)["\']', body, re.I)
                ext_links = re.findall(r'<link[^>]*href=["\']([^"\']+)["\']', body, re.I)

                for src in ext_scripts:
                    if src.startswith('http') and not any(safe in src for safe in
                            ['googleapis.com', 'gstatic.com', 'jquery.com', 'cloudflare.com',
                             'jsdelivr.net', 'unpkg.com', 'cdnjs.cloudflare.com', 'bootstrapcdn.com',
                             'wp.com', 'wordpress.org', 'gravatar.com', 'google-analytics.com',
                             'googletagmanager.com', 'facebook.net', 'twitter.com']):
                        findings.append({'type': f'Unknown External Script: {src[:60]}', 'severity': 'Medium'})
    except Exception:
        pass
    return findings


async def scan_malware(session, url):
    console.print(f"\n[bold cyan]--- Malware Scanner ---[/bold cyan]")
    all_f = []

    console.print(f"  [cyan]Scanning for malware patterns...[/cyan]")
    all_f.extend(await _scan_page_malware(session, url))

    console.print(f"  [cyan]Checking external resources...[/cyan]")
    all_f.extend(await _scan_external_resources(session, url))

    console.print(f"  [cyan]Google Safe Browsing reference...[/cyan]")
    all_f.extend(await _check_google_safebrowsing(session, url))

    for f in all_f:
        if f['severity'] != 'Info':
            color = 'red' if f['severity'] == 'Critical' else 'yellow'
            console.print(f"  [{color}]⚠ {f['type']}[/{color}]")
    if not [f for f in all_f if f['severity'] in ('Critical', 'High')]:
        console.print(f"\n  [green]✓ No malware detected[/green]")
    return {'findings': all_f}
